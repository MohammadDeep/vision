{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadDeep/vision/blob/main/vision_dataset_model_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDPro4Z3gU4m",
        "outputId": "01912475-f5a4-4afa-ab14-d41f7e1cb30f"
      },
      "outputs": [],
      "source": [
        "from Config import image_dir, image_val_dir,ann_file, ann_file_val\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSs7eTSM8Kwm",
        "outputId": "a35fd082-d5ff-486f-92b5-a5470c65c5ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=18.63s)\n",
            "creating index...\n",
            "index created!\n",
            "[{'supercategory': 'person', 'id': 1, 'name': 'person'}, {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'vehicle', 'id': 3, 'name': 'car'}, {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'}, {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'}, {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'}, {'supercategory': 'vehicle', 'id': 7, 'name': 'train'}, {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'}, {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'}, {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'}, {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'}, {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'}, {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'}, {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'}, {'supercategory': 'animal', 'id': 16, 'name': 'bird'}, {'supercategory': 'animal', 'id': 17, 'name': 'cat'}, {'supercategory': 'animal', 'id': 18, 'name': 'dog'}, {'supercategory': 'animal', 'id': 19, 'name': 'horse'}, {'supercategory': 'animal', 'id': 20, 'name': 'sheep'}, {'supercategory': 'animal', 'id': 21, 'name': 'cow'}, {'supercategory': 'animal', 'id': 22, 'name': 'elephant'}, {'supercategory': 'animal', 'id': 23, 'name': 'bear'}, {'supercategory': 'animal', 'id': 24, 'name': 'zebra'}, {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'}, {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'}, {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'}, {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'}, {'supercategory': 'accessory', 'id': 32, 'name': 'tie'}, {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'}, {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'}, {'supercategory': 'sports', 'id': 35, 'name': 'skis'}, {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'}, {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'}, {'supercategory': 'sports', 'id': 38, 'name': 'kite'}, {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'}, {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'}, {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'}, {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'}, {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'}, {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'}, {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'}, {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'}, {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'}, {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'}, {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'}, {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'}, {'supercategory': 'food', 'id': 52, 'name': 'banana'}, {'supercategory': 'food', 'id': 53, 'name': 'apple'}, {'supercategory': 'food', 'id': 54, 'name': 'sandwich'}, {'supercategory': 'food', 'id': 55, 'name': 'orange'}, {'supercategory': 'food', 'id': 56, 'name': 'broccoli'}, {'supercategory': 'food', 'id': 57, 'name': 'carrot'}, {'supercategory': 'food', 'id': 58, 'name': 'hot dog'}, {'supercategory': 'food', 'id': 59, 'name': 'pizza'}, {'supercategory': 'food', 'id': 60, 'name': 'donut'}, {'supercategory': 'food', 'id': 61, 'name': 'cake'}, {'supercategory': 'furniture', 'id': 62, 'name': 'chair'}, {'supercategory': 'furniture', 'id': 63, 'name': 'couch'}, {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'}, {'supercategory': 'furniture', 'id': 65, 'name': 'bed'}, {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'}, {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'}, {'supercategory': 'electronic', 'id': 72, 'name': 'tv'}, {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'}, {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'}, {'supercategory': 'electronic', 'id': 75, 'name': 'remote'}, {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'}, {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'}, {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'}, {'supercategory': 'appliance', 'id': 79, 'name': 'oven'}, {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'}, {'supercategory': 'appliance', 'id': 81, 'name': 'sink'}, {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'}, {'supercategory': 'indoor', 'id': 84, 'name': 'book'}, {'supercategory': 'indoor', 'id': 85, 'name': 'clock'}, {'supercategory': 'indoor', 'id': 86, 'name': 'vase'}, {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'}, {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'}, {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'}, {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]\n"
          ]
        }
      ],
      "source": [
        "from pycocotools.coco import COCO\n",
        "if __name__ == \"__main__\":\n",
        "  # بارگذاری فایل آنوتیشن COCO (آدرس فایل خود را قرار دهید)\n",
        "  coco = COCO(ann_file_val)  # آدرس فایل آنوتیشن خود را قرار دهید\n",
        "\n",
        "  # استخراج لیست کلاس‌ها (دسته‌بندی‌ها)\n",
        "  categories = coco.loadCats(coco.getCatIds())\n",
        "\n",
        "\n",
        "  print(categories)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMXj4frpBodq"
      },
      "source": [
        "# create folber dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GllXru_AYG7b"
      },
      "outputs": [],
      "source": [
        "from pycocotools.coco import COCO\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "from pycocotools.coco import COCO\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd9jxkI6i_tY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class getDataFoalberCoco:\n",
        "  def __init__(self,\n",
        "               image_dir: str ,\n",
        "               ann_file_1 : str,\n",
        "               list_catecoy : list,\n",
        "               destination_dir : str\n",
        "                ):\n",
        "    self.image_dir = image_dir\n",
        "    self.ann_file  = ann_file_1\n",
        "    self.list_catecoy = list_catecoy\n",
        "    self.destination_dir = destination_dir\n",
        "\n",
        "\n",
        "  def get_image_label(self):\n",
        "    '''\n",
        "    get data and label in list\n",
        "    self.list_data[{'image':img,'anns':anns}, ...]\n",
        "    '''\n",
        "    if  hasattr(self, 'list_data'):\n",
        "      return None\n",
        "    print('in function   :  get_image_lable')\n",
        "    with open(self.ann_file, 'r') as f:\n",
        "      data = json.load(f)\n",
        "    coco = COCO(self.ann_file)\n",
        "    self.list_data = []\n",
        "    for i in range(len(data['images'])):\n",
        "      # Find image ID based on file name\n",
        "      image_id = data['images'][i]['id']\n",
        "      '''\n",
        "      for image_info in data['images']:\n",
        "          if image_info['file_name'] == '000000397133.jpg':\n",
        "              image_id = image_info['id']\n",
        "              break\n",
        "      '''\n",
        "      if image_id is not None:\n",
        "          # Load image data using the found image ID\n",
        "          img = coco.loadImgs(image_id)[0]\n",
        "          anns = coco.loadAnns(coco.getAnnIds(imgIds=img['id']))\n",
        "          #cats = coco.loadCats(coco.getCatIds())\n",
        "          #labels = [cat['name'] for cat in cats]\n",
        "\n",
        "          self.list_data.append({'image':img,'anns':anns})\n",
        "      else:\n",
        "          print(f\"Image with number image  {i}  not found in the dataset.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def get_category_name(self):\n",
        "    '''\n",
        "     list of category_id\n",
        "    -> self.caregory_list\n",
        "    '''\n",
        "    if   hasattr(self, 'category_list') :\n",
        "      return None\n",
        "    print('in function   :  get_category_name')\n",
        "    self.get_image_label()\n",
        "    self.category_list = []\n",
        "\n",
        "    for i  in self.list_data:\n",
        "      list_new = [i1['category_id']for i1 in i['anns']]\n",
        "      self.category_list.append(list_new)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def copy_image(self, data, categore_name : str):\n",
        "      \"\"\"Copies images to a new directory based on the provided list_data.\n",
        "      Args:\n",
        "          list_data: The list of image data from the COCO dataset.\n",
        "          destination_dir: The directory to copy the images to.\n",
        "      \"\"\"\n",
        "      destination_dir1 = os.path.join(self.destination_dir, categore_name)\n",
        "      if not os.path.exists(destination_dir1):\n",
        "          os.makedirs(destination_dir1)\n",
        "\n",
        "\n",
        "\n",
        "      image_info = data['image']\n",
        "      image_path = os.path.join(self.image_dir, image_info['file_name'])\n",
        "\n",
        "      if os.path.exists(image_path):\n",
        "          destination_path = os.path.join(destination_dir1, image_info['file_name'])\n",
        "          shutil.copy2(image_path, destination_path) # copy2 preserves metadata\n",
        "          #print(f\"Copied {image_info['file_name']} to {destination_path}\")\n",
        "      else:\n",
        "          print(f\"Warning: Image file not found: {image_path}\")\n",
        "\n",
        "\n",
        "  def get_new_category_list(self):\n",
        "    '''\n",
        "    -> self.new_category_list\n",
        "    '''\n",
        "    if hasattr(self, 'new_category_list'):\n",
        "      return None\n",
        "    print('in function   :  get_new_category_list')\n",
        "    self.get_category_name()\n",
        "    self.new_category_list = []\n",
        "    for i in self.category_list:\n",
        "\n",
        "      a = np.array(i)\n",
        "      b = np.array(self.list_catecoy)\n",
        "\n",
        "      label = np.intersect1d(a, b)\n",
        "      label = label if label.size > 0 else [-1]\n",
        "      self.new_category_list.append(label)\n",
        "\n",
        "\n",
        "  def create_dataset_folber(self):\n",
        "    '''\n",
        "    create and save dataset image folber\n",
        "    '''\n",
        "    self.get_new_category_list()\n",
        "    len_all_data  = len(self.new_category_list)\n",
        "    for i in tqdm(range(len_all_data)):\n",
        "      for i1 in self.new_category_list[i]:\n",
        "        self.copy_image(data = self.list_data[i], categore_name  =  str(i1))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljchtGKAvJZW",
        "outputId": "897837a8-e323-4c0c-9365-bf00770e6a9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in function   :  get_new_category_list\n",
            "in function   :  get_category_name\n",
            "in function   :  get_image_lable\n",
            "loading annotations into memory...\n",
            "Done (t=1.92s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:03<00:00, 1480.00it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "  '''\n",
        "\n",
        "  train_data = getDataFoalberCoco(\n",
        "               image_dir  ,\n",
        "               ann_file,\n",
        "               [1],\n",
        "               '/content/data_set/train_dataset')\n",
        "\n",
        "  train_data.create_dataset_folber()\n",
        "\n",
        "  '''\n",
        "  val_data =  getDataFoalberCoco(\n",
        "               image_val_dir  ,\n",
        "               ann_file_val,\n",
        "               [1],\n",
        "               '/content/data_set/val_dataset')\n",
        "\n",
        "  val_data.create_dataset_folber()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W1riBVKyutQ"
      },
      "source": [
        "# برش داده تصاویر"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkhZ1n4t3oZy"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from collections import OrderedDict\n",
        "from typing import Optional, List, Tuple\n",
        "import psutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "\n",
        "\n",
        "class CutImage:\n",
        "    \"\"\"\n",
        "    Efficiently cut and composite objects from images based on COCO annotations,\n",
        "    using a limited-size LRU cache with memory-aware eviction.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_dir: str,\n",
        "        bake_dir: str,\n",
        "        ann_file: str,\n",
        "        category_id: int,\n",
        "        destination_dir: str,\n",
        "        cache_size: int = 1000,\n",
        "        memory_threshold: float = 95.0 # [0, 100]\n",
        "    ):\n",
        "        # Initialize paths\n",
        "        self.image_dir = Path(image_dir)\n",
        "        self.bake_dir = Path(bake_dir)\n",
        "        self.ann_file = Path(ann_file)\n",
        "        self.destination_dir = Path(destination_dir)\n",
        "        self.category_id = category_id\n",
        "        self.bboxes_image :dict[str , List[List[float]]] = {}\n",
        "        # LRU cache for loaded images\n",
        "        self._cache: OrderedDict[Path, np.ndarray] = OrderedDict()\n",
        "        self._cache_size = cache_size\n",
        "        self._use_ram = True\n",
        "        # Threshold for system memory usage (%) to trigger eviction\n",
        "        self._memory_threshold = memory_threshold\n",
        "\n",
        "        # Preload bake image paths for random selection\n",
        "        self._bake_paths: List[Path] = (\n",
        "            list(self.bake_dir.glob(\"*.jpg\")) +\n",
        "            list(self.bake_dir.glob(\"*.png\")) +\n",
        "            list(self.bake_dir.glob(\"*.jpeg\"))\n",
        "        )\n",
        "\n",
        "        # Initialize COCO API\n",
        "        self._coco = COCO(str(self.ann_file))\n",
        "\n",
        "    def _read_image(self, path: Path) -> Optional[np.ndarray]:\n",
        "        \"\"\"\n",
        "        Read image from disk with LRU caching. Evict oldest entries\n",
        "        when cache is full or system memory usage exceeds threshold.\n",
        "        \"\"\"\n",
        "        # Cache hit: move to end (most recently used)\n",
        "        if path in self._cache:\n",
        "            img = self._cache.pop(path)\n",
        "            self._cache[path] = img\n",
        "            return img\n",
        "\n",
        "        # Check system memory and cache size for eviction\n",
        "        mem_percent = psutil.virtual_memory().percent\n",
        "        # Evict if memory usage too high\n",
        "        while self._cache and mem_percent >= self._memory_threshold:\n",
        "            evicted_path, _ = self._cache.popitem(last=False)\n",
        "            if self._use_ram :\n",
        "              self._use_ram  = False\n",
        "\n",
        "              print(f\"\\n High memory usage {mem_percent:.1f}%  , evicted {evicted_path}\")\n",
        "            mem_percent = psutil.virtual_memory().percent\n",
        "        # Evict oldest if cache full\n",
        "        if len(self._cache) >= self._cache_size:\n",
        "\n",
        "            evicted_path, _ = self._cache.popitem(last=False)\n",
        "            # Optional: print(f\"Evicted from cache due to size limit: {evicted_path}\")\n",
        "\n",
        "        # Cache miss: load from disk\n",
        "        img = cv2.imread(str(path))\n",
        "        if img is None:\n",
        "            print(f\"Warning: failed to read {path}\")\n",
        "            return None\n",
        "\n",
        "        # Insert newly read image as most recently used\n",
        "        self._cache[path] = img\n",
        "        return img\n",
        "\n",
        "    def _get_random_bake(self) -> Path:\n",
        "        \"\"\"Return a random bake image path.\"\"\"\n",
        "        if not self._bake_paths:\n",
        "            raise FileNotFoundError(f\"No bake images in {self.bake_dir}\")\n",
        "        return random.choice(self._bake_paths)\n",
        "\n",
        "    @staticmethod\n",
        "    def _merge_mask(\n",
        "        shape: Tuple[int, int],\n",
        "        segmentations: List[List[List[float]]]\n",
        "        ) -> Tuple[np.ndarray, int, int, int, int]:\n",
        "        \"\"\"\n",
        "        Combine multiple polygon segmentations into one mask and compute bounding box.\n",
        "        Returns mask, x, y, w, h\n",
        "        \"\"\"\n",
        "        mask = np.zeros(shape, dtype=np.uint8)\n",
        "        points = []\n",
        "        # Fill each polygon onto the mask\n",
        "        for seg in segmentations:\n",
        "            if isinstance(seg, list):\n",
        "                pts = np.array(seg, dtype=np.int32).reshape(-1, 2)\n",
        "                cv2.fillPoly(mask, [pts], 255)\n",
        "                points.append(pts)\n",
        "        if not points:\n",
        "            # No valid segments, entire image\n",
        "            return mask, 0, 0, shape[1], shape[0]\n",
        "        all_pts = np.vstack(points)\n",
        "        x, y, w, h = cv2.boundingRect(all_pts)\n",
        "        return mask, x, y, w, h\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_and_crop(\n",
        "        image: np.ndarray,\n",
        "        mask: np.ndarray,\n",
        "        x: int,\n",
        "        y: int,\n",
        "        w: int,\n",
        "        h: int\n",
        "        ) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Apply mask to image and crop to bounding box.\n",
        "        \"\"\"\n",
        "        extracted = cv2.bitwise_and(image, image, mask=mask)\n",
        "        cropped_img = extracted[y:y+h, x:x+w]\n",
        "        cropped_mask = mask[y:y+h, x:x+w]\n",
        "        return cropped_img, cropped_mask\n",
        "\n",
        "    @staticmethod\n",
        "    def _add_padding(\n",
        "        img: np.ndarray,\n",
        "        mask: np.ndarray\n",
        "        ) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Add random padding around the cropped image and mask.\n",
        "        \"\"\"\n",
        "        h, w = img.shape[:2]\n",
        "        max_edge = max(h, w)\n",
        "        pad_extra = random.randint(0, max_edge)\n",
        "        target = max_edge + pad_extra\n",
        "\n",
        "        pad_vert = target - h\n",
        "        pad_horiz = target - w\n",
        "        top = random.randint(0, pad_vert)\n",
        "        left = random.randint(0, pad_horiz)\n",
        "        bottom = pad_vert - top\n",
        "        right = pad_horiz - left\n",
        "\n",
        "        img_padded = cv2.copyMakeBorder(\n",
        "            img, top, bottom, left, right,\n",
        "            cv2.BORDER_CONSTANT, value=[0, 0, 0]\n",
        "        )\n",
        "        mask_padded = cv2.copyMakeBorder(\n",
        "            mask, top, bottom, left, right,\n",
        "            cv2.BORDER_CONSTANT, value=0\n",
        "        )\n",
        "        return img_padded, mask_padded\n",
        "\n",
        "    @staticmethod\n",
        "    def _resize(\n",
        "        img: np.ndarray,\n",
        "        size: int\n",
        "        ) -> np.ndarray:\n",
        "        \"\"\"Resize image to (size, size).\"\"\"\n",
        "        return cv2.resize(img, (size, size))\n",
        "\n",
        "    def _save(\n",
        "        self,\n",
        "        img: np.ndarray,\n",
        "        name: str,\n",
        "        folber:str = None\n",
        "        ) -> None:\n",
        "        \"\"\"Save image with JPEG quality 95.\"\"\"\n",
        "        if folber is not None:\n",
        "          dir = self.destination_dir / folber\n",
        "        else:\n",
        "          dir = self.destination_dir\n",
        "        dir = Path(dir)\n",
        "        dir.mkdir(parents=True, exist_ok=True)\n",
        "        out_path = dir / name\n",
        "        cv2.imwrite(str(out_path), img, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "\n",
        "    def create_cut_images(\n",
        "        self,\n",
        "        min_area: int = 5000,\n",
        "        show: bool = False,\n",
        "        save: bool = True\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        Process annotations, extract objects, composite with random bakes,\n",
        "        and optionally display or save results.\n",
        "        \"\"\"\n",
        "        # Get annotation IDs for the target category\n",
        "        ann_ids = self._coco.getAnnIds(catIds=[self.category_id])\n",
        "        anns = self._coco.loadAnns(ann_ids)\n",
        "\n",
        "        for idx, ann in enumerate(tqdm(anns, desc=\"Processing annotations\")):\n",
        "            if ann.get('area', 0) < min_area:\n",
        "                continue\n",
        "\n",
        "            # Load front image\n",
        "            img_info = self._coco.loadImgs(ann['image_id'])[0]\n",
        "            front_path = self.image_dir / img_info['file_name']\n",
        "            front_img = self._read_image(front_path)\n",
        "            if front_img is None:\n",
        "                continue\n",
        "\n",
        "            # Merge all segmentations into one mask\n",
        "            mask, x, y, w, h = self._merge_mask(\n",
        "                front_img.shape[:2],\n",
        "                ann.get('segmentation', [])  # list of polygons\n",
        "            )\n",
        "\n",
        "            # Extract and crop object\n",
        "            #mask1 = cv2.bitwise_not(mask)\n",
        "            cropped, mask_cropped = self._extract_and_crop(front_img, mask, x, y, w, h)\n",
        "            padded, mask_padded = self._add_padding(cropped, mask_cropped)\n",
        "\n",
        "            # Composite with random bake background\n",
        "            mask_inv = cv2.bitwise_not(mask_padded)\n",
        "            bake_img = self._read_image(self._get_random_bake())\n",
        "            if bake_img is None:\n",
        "                continue\n",
        "            bake_resized = self._resize(bake_img, padded.shape[0])\n",
        "            bake_part = cv2.bitwise_and(bake_resized, bake_resized, mask=mask_inv)\n",
        "            final = cv2.bitwise_or(bake_part, padded)\n",
        "\n",
        "            # Show or save\n",
        "            if show:\n",
        "                rgb = cv2.cvtColor(final, cv2.COLOR_BGR2RGB)\n",
        "                plt.figure(figsize=(6, 6))\n",
        "                plt.imshow(rgb)\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "            if save:\n",
        "                name = f\"cut_indx_{idx}_imageName_{img_info['file_name']}\"\n",
        "                self._save(final, name, 'cut_image')\n",
        "\n",
        "\n",
        "    def create_cut_box_images(\n",
        "        self,\n",
        "        min_area: int = 5000,\n",
        "        max_area: int = 10000000,\n",
        "        random_n:float = 0.2,\n",
        "        show: bool = False,\n",
        "        save: bool = True,\n",
        "        random_size_box_cut = False\n",
        "        ) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Process annotations, extract objects, composite with random bakes,\n",
        "        and optionally display or save results.\n",
        "        \"\"\"\n",
        "        # Get annotation IDs for the target category\n",
        "        ann_ids = self._coco.getAnnIds(catIds=[self.category_id])\n",
        "        anns = self._coco.loadAnns(ann_ids)\n",
        "        self.bboxes_image :dict[str , List[List[float]]] = {}\n",
        "        for idx, ann in enumerate(tqdm(anns, desc=\"Processing annotations\")):\n",
        "\n",
        "            # Load front image\n",
        "            img_info = self._coco.loadImgs(ann['image_id'])[0]\n",
        "\n",
        "\n",
        "            front_path = self.image_dir / img_info['file_name']\n",
        "            front_img = self._read_image(front_path)\n",
        "            if front_img is None:\n",
        "                continue\n",
        "\n",
        "            # Merge all segmentations into one mask\n",
        "\n",
        "            bbox = ann.get('bbox', [])  # list of polygons\n",
        "            x, y, w, h = [int(v) for v in bbox]\n",
        "\n",
        "\n",
        "\n",
        "            if random_size_box_cut:\n",
        "              random_size = random.randint(0, int(random_n * max(w,h)))\n",
        "              size_cut  = max(w,h) + random_size\n",
        "\n",
        "              #print('w')\n",
        "              y1 = y - random.randint(0, max(int(w-h) , 0) + random_size)\n",
        "\n",
        "              y = max(y1, 0)\n",
        "\n",
        "              #print('h')\n",
        "              x1 = x - random.randint(0, max(int(h-w), 0) + random_size)\n",
        "\n",
        "              x = max(x1, 0)\n",
        "              w = size_cut\n",
        "              h = w\n",
        "\n",
        "            # 4. برش مستقیم با استفاده از اسلایس NumPy\n",
        "            y_end = min(y + h, front_img.shape[0])\n",
        "            x_end = min(x + w, front_img.shape[1])\n",
        "            cropped = front_img[y:y_end, x:x_end]\n",
        "\n",
        "            # add bbox to list of box image\n",
        "            self.bboxes_image.setdefault(img_info['file_name'], []).append(bbox)\n",
        "\n",
        "            # Show or save\n",
        "            if show:\n",
        "                rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
        "                plt.figure(figsize=(6, 6))\n",
        "                plt.imshow(rgb)\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "            if save and ann.get('area', 0) > min_area and ann.get('area', 0) < max_area :\n",
        "\n",
        "                name = f\"cut_area_{ann.get('area', 0)}_idx_{idx}_imageName_{img_info['file_name']}\"\n",
        "                self._save(cropped, name , 'box_image')\n",
        "\n",
        "    def create_cut_box_bake(\n",
        "        self,\n",
        "        show: bool = False,\n",
        "        save: bool = True,\n",
        "        ) -> None:\n",
        "      if len(self.bboxes_image) == 0 :\n",
        "        print('Creat in  self.bboxes_image')\n",
        "        print('you shoud de run function create_cut_box_images() ')\n",
        "        return None\n",
        "\n",
        "      for idx, img_name in enumerate(tqdm(self.bboxes_image.keys(), desc=\"Processing annotations\")):\n",
        "\n",
        "        bake_img = self._read_image(self.image_dir / img_name)\n",
        "        if bake_img is None:\n",
        "            continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        h_img, w_img = bake_img.shape[:2]\n",
        "        mask = np.zeros((h_img, w_img), dtype=np.uint8)\n",
        "\n",
        "        for bbox in self.bboxes_image[img_name]:\n",
        "            x, y, w, h = [int(v) for v in bbox]\n",
        "            mask[y:y+h, x:x+w] = 255\n",
        "            #bake_img[y:y+h, x:x+w] = 0\n",
        "        random_img = self._read_image(self._get_random_bake())\n",
        "\n",
        "\n",
        "        random_img = cv2.resize(random_img, (w_img, h_img))\n",
        "        random_img = cv2.bitwise_and(random_img, random_img, mask=mask)\n",
        "        mask_info = cv2.bitwise_not(mask)\n",
        "        img_bake = cv2.bitwise_and(bake_img, bake_img, mask=mask_info)\n",
        "        final = cv2.bitwise_or(random_img, img_bake, mask=None)\n",
        "\n",
        "\n",
        "        # Show or save\n",
        "        if show:\n",
        "            rgb = cv2.cvtColor(final, cv2.COLOR_BGR2RGB)\n",
        "            plt.figure(figsize=(6, 6))\n",
        "            plt.imshow(rgb)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        if save:\n",
        "            name = f\"bake_idx_{idx}_imageName_{img_name}\"\n",
        "            self._save(final, name, 'bake_image_Not')\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"\n",
        "        Clear and delete all large internal attributes so that\n",
        "        the garbage collector can reclaim their memory.\n",
        "        \"\"\"\n",
        "        import gc\n",
        "\n",
        "        # 1) LRU cache of loaded images\n",
        "        if hasattr(self, '_cache'):\n",
        "            self._cache.clear()    # حذف همه‌ی تصاویر از OrderedDict\n",
        "            del self._cache        # حذف ارجاع به خودِ OrderedDict\n",
        "\n",
        "        # 2) دیکشنری bboxes_image\n",
        "        if hasattr(self, 'bboxes_image'):\n",
        "            self.bboxes_image.clear()\n",
        "            del self.bboxes_image\n",
        "\n",
        "        # 3) لیست مسیرهای تصاویر bake\n",
        "        if hasattr(self, '_bake_paths'):\n",
        "            self._bake_paths.clear()\n",
        "            del self._bake_paths\n",
        "\n",
        "        # 4) شیء COCO (حاوی داده‌های آنتیشن)\n",
        "        if hasattr(self, '_coco'):\n",
        "            del self._coco\n",
        "\n",
        "        # 5) حذف مقادیر مسیرها و پارامترهای دیگر (در صورت نیاز)\n",
        "        for attr in ['image_dir', 'bake_dir', 'ann_file', 'destination_dir']:\n",
        "            if hasattr(self, attr):\n",
        "                delattr(self, attr)\n",
        "\n",
        "        # 6) حذف تنظیمات کش/رم\n",
        "        for attr in ['_cache_size', '_memory_threshold', '_use_ram', 'category_id']:\n",
        "            if hasattr(self, attr):\n",
        "                delattr(self, attr)\n",
        "\n",
        "        # 7) حذف ماژول‌های import شده به عنوان attribute (در صورت بود)\n",
        "        #    — معمولاً نیازی نیست مگر خودتان در __init__ ذخیره کرده باشید\n",
        "\n",
        "        # 8) اجرای اجباری garbage collection\n",
        "        gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtGIdNxJBZ7w",
        "outputId": "cad904a3-2e21-4de6-a7e9-700cfcd27f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.52s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing annotations:   0%|          | 12/11004 [00:00<01:34, 116.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " High memory usage 30.9%  , evicted data/val2017/000000425226.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing annotations: 100%|██████████| 11004/11004 [00:52<00:00, 211.50it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  imm1 =  CutImage(image_dir = './data/val2017',\n",
        "                bake_dir = '/content/data_set/dav_dataset/-1',\n",
        "                ann_file = './data/annotations/instances_val2017.json',\n",
        "                category_id = 1,\n",
        "                destination_dir = '/content/cut4',\n",
        "                cache_size= 10000,\n",
        "                memory_threshold = 95\n",
        "                )\n",
        "  imm1.create_cut_box_images( min_area=10000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQIzY9_FBXzJ",
        "outputId": "c95afe93-047d-4add-ab8b-707326ad1856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.70s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing annotations: 100%|██████████| 11004/11004 [00:21<00:00, 505.20it/s]\n",
            "Processing annotations: 100%|██████████| 2693/2693 [00:24<00:00, 110.42it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  imm1 =  CutImage(image_dir = './data/val2017',\n",
        "                bake_dir = '/content/data_set/val_dataset/-1',\n",
        "                ann_file = './data/annotations/instances_val2017.json',\n",
        "                category_id = 1,\n",
        "                destination_dir = '/content/cut4',\n",
        "                cache_size= 10000,\n",
        "                memory_threshold =95\n",
        "                )\n",
        "  imm1.create_cut_box_images( min_area=10000)\n",
        "  imm1.create_cut_box_bake()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1KnMOJwvMOG",
        "outputId": "c10101fc-8ed9-43b1-c0b5-40ef3e9794da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.50s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing annotations:   0%|          | 23/11004 [00:00<00:49, 222.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " High memory usage 32.4%  , evicted data/val2017/000000425226.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing annotations: 100%|██████████| 11004/11004 [00:39<00:00, 280.53it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  imm1 =  CutImage(image_dir = './data/val2017',\n",
        "                bake_dir = '/content/data_set/val_dataset/-1',\n",
        "                ann_file = './data/annotations/instances_val2017.json',\n",
        "                category_id = 1,\n",
        "                destination_dir = '/content/cut4',\n",
        "                cache_size= 10000,\n",
        "                memory_threshold = 95\n",
        "                )\n",
        "\n",
        "  imm1.create_cut_images( 10000 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYULu9zxBh7z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPYk1ymuZDRoL24Msqn0ZCl",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
